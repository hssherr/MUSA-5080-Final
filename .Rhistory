test <- crime_cnts %>%
complete(GEOID, text_general_code, fill = list(count = 0))
complete('GEOID', text_general_code, fill = list(count = 0))
test <- crime_cnts %>%
complete(GEOID, text_general_code)
test <- crime_cnts %>%
complete(data = ., GEOID, text_general_code)
test <- crime_cnts %>%
complete(data = ., GEOID, text_general_code)
test <- crime_cnts %>%
complete(data = ., GEOID, text_general_code)
test <- complete(data = crime_cnts, GEOID, text_general_code)
# summarize by the number of each type of crime per census tract
crime_cnts <- crime_tract %>%
st_drop_geometry() %>%
group_by(GEOID, text_general_code) %>%
summarise(count = n()) %>%
ungroup()
test <- complete(data = crime_cnts, GEOID, text_general_code)
length(unique(crime_cnts$text_general_code))
31*408
length(unique(crime_cnts$GEOID))
unique(crime_cnts$GEOID) %in% tracts$GEOID
crime_cnts %>% filter(unique(crime_cnts$GEOID) %in% tracts$GEOID)
crime_cnts %>% subset(crime_cnts$GEOID) %in% tracts$GEOID)
crime_cnts %>% subset(crime_cnts$GEOID) %in% tracts$GEOID))
crime_cnts %>% subset(crime_cnts$GEOID %in% tracts$GEOID)
crime_cnts %>% subset(!(crime_cnts$GEOID %in% tracts$GEOID))
# join tract geoid to crimes
crime_tract <- st_join(crime, tracts, join = st_intersects) %>%
filter(!is.na(GEOID))
# summarize by the number of each type of crime per census tract
crime_cnts <- crime_tract %>%
st_drop_geometry() %>%
group_by(GEOID, text_general_code) %>%
summarise(count = n()) %>%
ungroup() %>%
complete(data = crime_cnts, GEOID, text_general_code, fill = list(count = 0))
# join tract geoid to crimes and filter out those not in Philly
crime_tract <- st_join(crime, tracts, join = st_intersects) %>%
filter(!is.na(GEOID))
# summarize by the number of each type of crime per census tract
crime_cnts <- crime_tract %>%
st_drop_geometry() %>%
group_by(GEOID, text_general_code) %>%
summarise(count = n()) %>%
ungroup() %>%
complete(data = crime_cnts, GEOID, text_general_code)
test <- crime_cnts %>%
complete(data = crime_cnts, GEOID, text_general_code)
# summarize by the number of each type of crime per census tract
crime_cnts <- crime_tract %>%
st_drop_geometry() %>%
group_by(GEOID, text_general_code) %>%
summarise(count = n()) %>%
ungroup() %>%
complete(data = ., GEOID, text_general_code)
# summarize by the number of each type of crime per census tract
crime_cnts <- crime_tract %>%
st_drop_geometry() %>%
group_by(GEOID, text_general_code) %>%
summarise(count = n()) %>%
ungroup() %>%
complete(data = ., GEOID, text_general_code, fill = list(count = 0))
unique(crime_cnts$text_general_code)
unique(crime_cnts$text_general_code) %>% length()
unique(crime_cnts$GEOID) %>% length()
408*31
mva <- st_read('./data/mva_2023.geojson', quiet = T)
View(mva)
plot(mva[,"Shape__Area"])
unique(mva$geoid)
unique(mva$geoid) %>% length
tracts$GEOID
test <- mva %>% subset(geoid %in% tracts$GEOID)
unique(mva$geoid)  %in% tracts$GEOID
View(tracts)
View(mva)
nchar('421010001011')
plot(mva$geometry)
plot(tracts$geometry)
# read in results of
mva <- st_read('./data/mva_2023.geojson', quiet = T) %>%
st_transform(2272)
plot(mva$geometry)
plot(tracts$geometry)
mutate(GEOID_Tract = substr(geoid, 1, nchar(geoid)-1)
# the data is at the block group level
# GEOID (12 digits) = tract (11 digits) + block grp (1 digit)
mva <- mva %>%
# the data is at the block group level
# GEOID (12 digits) = tract (11 digits) + block grp (1 digit)
mva <- mva %>%
mutate(GEOID_Tract = substr(geoid, 1, nchar(geoid)-1))
unique(mva$GEOID_Tract)
unique(mva$GEOID_Tract) %>% length()
is.na(mva$GEOID_Tract)
is.na(mva$GEOID_Tract) sum()
is.na(mva$GEOID_Tract) %>% sum()
mva$GEOID_Tract %in% tracts$GEOID
sum(mva$GEOID_Tract %in% tracts$GEOID)
sum(unique(mva$GEOID_Tract) %in% tracts$GEOID)
unique(mva$GEOID_Tract) %in% tracts$GEOID
test <- unique(mva$GEOID_Tract) %>% subset(unique(mva$GEOID_Tract) %in% tracts$GEOID)
test <- unique(mva$GEOID_Tract) %>% subset(!(unique(mva$GEOID_Tract) %in% tracts$GEOID))
test <- unique(tracts$GEOID) %>% subset(!(unique(mva$GEOID_Tract) %in% tracts$GEOID))
test <- unique(tracts$GEOID) %>% subset(!(tracts$GEOID %in% unique(mva$GEOID_Tract)))
tracts$test <- ifelse(tracts$GEOID == test, 1, 0)
plot(tracts[,"test"])
hca <- st_read('./data/HousingCounselingAgencies.geojson', quiet = T) %>%
st_transform(2272)
View(hca)
tracts_cent <- tracts %>%
st_centroid()
View(tracts_cent)
tracts %>% select(-test)
hca_dist <- tracts %>%
st_d
tracts <- tracts %>% select(-test)
tracts_cent <- tracts %>%
st_centroid()
hca_dist <- tracts %>%
st_distance(tracts, hca)
408*28
test <- st_distance(tracts, hca)
# create k-nearest neighbors function
get_knn_distance <- function(dist_matrix, k) {
apply(dist_matrix, 1, function(distances) {
mean(as.numeric(sort(distances)[1:k]))
})
}
hca_distmatrix <- st_distance(tracts, hca)
hca_distmatrix <- st_distance(tracts_cent, hca)
hca_dist <- tracts %>%
mutate(dist_1hca = get_knn_distance(hca_distmatrix, k = 1),
dist_3hca = get_knn_distance(hca_distmatrix, k = 3))
View(hca_dist)
```{r message=FALSE}
housing_cnts <- housing %>%
st_drop_geometry() %>%
group_by(GEOID, fiscal_year_complete) %>%
summarise(n_proj = n(),
total_units = sum(total_units)) %>%
mutate(n_proj_cum = ave(n_proj, FUN = cumsum),
total_units_cum = ave(total_units, FUN = cumsum)) %>%
filter(fiscal_year_complete >= 2020) %>%
left_join(tracts, by = "GEOID") %>%
st_as_sf(crs = 2272)
# join tract geoid to crimes and filter out those not in Philly
crime_tract <- st_join(crime, tracts, join = st_intersects) %>%
filter(!is.na(GEOID))
# summarize by the number of each type of crime per census tract
crime_cnts <- crime_tract %>%
st_drop_geometry() %>%
group_by(GEOID, text_general_code) %>%
summarise(count = n()) %>%
ungroup() %>%
complete(data = ., GEOID, text_general_code, fill = list(count = 0))
years <- seq(2020:2023)
years <- c(2020:2023)
years <- c(2018:2023)
years <- c(2020:2023)
fips_pa <- 42
acs_vars <- load_variables(year = 2023, dataset = 'acs5')
View(acs_vars)
vars <- c('pop_tot' = 'B01003_001',   # total tract population
'pop_white' = 'B02001_002', # white population (for %-non-white calc)
'units_tot' = 'B25001_001', # total housing units
'hh_tot' = 'B11001_001',    # total households
'hh_fam' = 'B11001_002')    # family households)
demo_vars <- map_df(years, function(y) {
get_acs(
geography = "state",
variables = vars,
year = y,
survey = "acs5",
progress_bar = F
) %>%
mutate(year = y)
})
View(demo_vars)
408*6
408*3
get_acs(
geography = "state",
variables = vars,
year = y,
survey = "acs5",
state = fips_pa,
county = fips_phl,
progress_bar = F
) %>%
mutate(year = y)
demo_vars <- map_df(years, function(y) {
get_acs(
geography = "state",
variables = vars,
year = y,
survey = "acs5",
state = fips_pa,
county = fips_phl,
progress_bar = F
) %>%
mutate(year = y)
})
View(demo_vars)
# designate FIPS codes for PA and Philly
fips_pa <- 42
fips_phl <- 101
# load tigris census tract boundaries
tracts <- tracts(state = 42, county = 101, year = 2020, progress_bar = F) %>%
select(GEOID) %>%
st_transform(2272)
# join to evictions dataset and make spatial
evictions <- left_join(evictions_df, tracts, by = "GEOID", ) %>%
st_as_sf()
demo_vars <- map_df(years, function(y) {
get_acs(
geography = "state",
variables = vars,
year = y,
survey = "acs5",
state = fips_pa,
county = fips_phl,
progress_bar = F
) %>%
mutate(year = y)
})
get_acs(
geography = "state",
variables = vars,
year = 2020,
survey = "acs5",
state = fips_pa,
county = fips_phl,
progress_bar = F
)
get_acs(
geography = "tract",
variables = vars,
year = 2020,
survey = "acs5",
state = fips_pa,
county = fips_phl,
progress_bar = F
)
years <- c(2020:2023)
acs_vars <- load_variables(year = 2023, dataset = 'acs5')
years <- c(2020:2023)
vars <- c('pop_tot' = 'B01003_001',   # total tract population
'pop_white' = 'B02001_002', # white population (for %-non-white calc)
'units_tot' = 'B25001_001', # total housing units
'hh_tot' = 'B11001_001',    # total households
'hh_fam' = 'B11001_002')    # family households)
demo_vars <- map_df(years, function(y) {
get_acs(
geography = "tract",
variables = vars,
year = y,
survey = "acs5",
state = fips_pa,
county = fips_phl,
progress_bar = F
) %>%
mutate(year = y)
})
408*4
View(demo_vars)
408*4*5
col = colors[2], border = "grey30")
plot(x = weather_complete$relh,
y = weather_complete$wspd,
pch = 16,
xlab = "Relative Humidity (%)",
ylab = "Wind Speed (mph)",
main = "Wind Speed vs. Relative Humidity (2024)",
col = alpha("black", 0.1))
# import a non-exhaustive list of commercial, retail, and office businesses from OSM
offices <- opq(st_bbox(phl_boundary %>% st_transform(4326))) %>%
add_osm_feature(key = "office") %>%
osmdata_sf(.)
shops <- opq(st_bbox(phl_boundary %>% st_transform(4326))) %>%
add_osm_feature(key = "shop") %>%
osmdata_sf(.)
# extract points from osm object, transform to EPSG 2272, and filter to PHL boundary
offices_pts <- offices[["osm_points"]] %>%
st_transform(2272) %>%
st_filter(phl_boundary, .predicate = st_within) %>%
mutate(type = "office")
shops_pts <- shops[["osm_points"]] %>%
st_transform(2272) %>%
st_filter(phl_boundary, .predicate = st_within) %>%
mutate(type = "shop")
# plot business locations
ggplot() +
geom_sf(data = phl_census, color = "grey80", fill = "grey95") +
geom_sf(data = offices_pts, aes(color = "Offices"), alpha = 0.25, size = 0.5) +
geom_sf(data = shops_pts, aes(color = "Shops"), alpha = 0.25, size = 0.5) +
scale_color_manual(name = "Business Types", values = c("Offices" = colors[1], "Shops" = colors[2])) +
labs(title = "Businesses in Philadelphia by Type") +
theme_void()
# combine businesses into one dataset and isolate census tract geometries/GEOIDs
businesses <- rbind(offices_pts %>% select(osm_id, name, type),
shops_pts %>% select(osm_id, name, type))
phl_tracts <- phl_census %>% select(GEOID)
# calculate business counts and densities per census tract
businesses_dens <- phl_tracts %>%
mutate(business_cnt = lengths(st_intersects(., businesses)),
business_dens = as.numeric(business_cnt/st_area(.))*2.78784e+7)
# plot business densitites spatially
ggplot() +
geom_sf(data = businesses_dens,
aes(fill = business_dens),
color = NA) +
scale_fill_viridis(name = "Business Density (#/sqmi)") +
labs(title = "Census Tract Business Density in Philadelphia (2025)") +
theme_void()
# Count trips by station-hour
trips_panel <- indego %>%
group_by(interval60, start_station, start_lat, start_lon) %>%
summarize(Trip_Count = n()) %>%
ungroup()
# How many station-hour observations?
cat("Original count of rows in Trips Panel:", nrow(trips_panel))
# How many unique stations?
cat("Unique stations in the dataset:", length(unique(trips_panel$start_station)))
# How many unique hours?
cat("Unique hours in the dataset:", length(unique(trips_panel$interval60)))
# find the number of stations and hours we need to represent
n_stations <- length(unique(trips_panel$start_station))
n_hours <- length(seq(min(trips_panel$interval60), max(trips_panel$interval60), by = "hour"))
expected_rows <- n_stations * n_hours
cat("Expected panel rows:", format(expected_rows, big.mark = ","), "\n")
cat("Current rows:", format(nrow(trips_panel), big.mark = ","), "\n")
cat("Missing rows:", format(expected_rows - nrow(trips_panel), big.mark = ","), "\n")
# join trip counts to expanded grid
study_panel <-
expand.grid(interval60 = seq(min(trips_panel$interval60),
max(trips_panel$interval60),
by = "hour"),
start_station = unique(trips_panel$start_station)
) %>%
left_join(., trips_panel %>% select(-c(start_lat, start_lon)),
by = c("interval60", "start_station")) %>%
mutate(Trip_Count = replace_na(Trip_Count, 0))
# get station lat and lon columns from indego df
stn_coords <- indego %>%
select(start_station, start_lat, start_lon) %>%
group_by(start_station) %>%
slice_head(n=1) %>%
ungroup()
# get the census tract each station is in
stn_points_filt_panel <- st_join(stn_points_filt, phl_tracts, join = st_within) %>%
left_join(., stn_coords,
by = "start_station") %>%
select(-in_phl) %>%
st_drop_geometry()
# fill in station-level attributes and variables
study_panel <- study_panel %>%
left_join(., stn_points_filt_panel,
by = "start_station")
study_panel <- study_panel %>%
mutate(
week = week(interval60),
month = month(interval60, label = TRUE),
dotw = wday(interval60, label = TRUE),
dotw_simple = factor(dotw,
levels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")),
hour = hour(interval60),
date = as.Date(interval60),
weekend = ifelse(dotw %in% c("Sat", "Sun"), 1, 0) %>% as.factor(),
rush_hour = ifelse(hour %in% c(7, 8, 9, 16, 17, 18), 1, 0) %>% as.factor()
)
study_panel <- study_panel %>%
left_join(., phl_census_select %>% st_drop_geometry(), by = "GEOID")
study_panel <- study_panel %>%
left_join(., businesses_dens %>% select(-business_cnt) %>% st_drop_geometry(),
by = "GEOID")
study_panel <- study_panel %>%
left_join(weather_complete, by = "interval60")
study_panel <- study_panel %>%
left_join(., holidays_all, by = "date") %>%
rename(holiday = type) %>%
mutate(holiday = replace_na(holiday, "none")) %>%
mutate(holiday = factor(holiday,
levels = c("none",
"holiday",
"festival",
"concert",
"sporting")))
# Sort by station and time
study_panel <- study_panel %>%
arrange(start_station, interval60)
# Create lag variables WITHIN each station
study_panel <- study_panel %>%
group_by(start_station) %>%
mutate(
lag1Hour = lag(Trip_Count, 1),
lag2Hours = lag(Trip_Count, 2),
lag3Hours = lag(Trip_Count, 3),
lag12Hours = lag(Trip_Count, 12),
lag1day = lag(Trip_Count, 24)
) %>%
ungroup()
# Remove rows with NA lags (first 24 hours for each station)
study_panel_complete <- study_panel %>%
filter(!is.na(lag1day))
cat("Rows after removing NA lags: ",
format(nrow(study_panel_complete), big.mark = ","), "\n\n",
"Percent data loss relative to original panel dataset after removing NA lags: ",
round((1-nrow(study_panel_complete)/nrow(study_panel))*100, 2), "%", sep = "", "\n")
# isolate data from one week in a high ridership week to view lag trends
example_station <- study_panel_complete %>%
filter(start_station == 3328 & week == 25)
# Plot actual vs lagged demand
ggplot(example_station, aes(x = interval60)) +
geom_line(aes(y = Trip_Count, color = "Current"), linewidth = 1) +
geom_line(aes(y = lag1Hour, color = "1 Hour Ago"), linewidth = 1, alpha = 0.7) +
geom_line(aes(y = lag1day, color = "24 Hours Ago"), linewidth = 1, alpha = 0.7) +
scale_color_manual(values = c(
"Current" = "#08519c",
"1 Hour Ago" = "#3182bd",
"24 Hours Ago" = "#6baed6"
)) +
labs(
title = "Temporal Lag Patterns at One Station",
subtitle = "Past demand predicts future demand",
x = "Date-Time",
y = "Trip Count",
color = "Time Period"
) +
theme_minimal()
spc_2024 <- study_panel_complete %>% filter(year(interval60) == 2024)
spc_2025 <- study_panel_complete %>% filter(year(interval60) == 2025)
# Which stations have trips in BOTH early and late periods?
early_stations <- spc_2024 %>%
filter(week < 40) %>%
filter(Trip_Count > 0) %>%
distinct(start_station) %>%
pull(start_station)
late_stations <- spc_2024 %>%
filter(week >= 40) %>%
filter(Trip_Count > 0) %>%
distinct(start_station) %>%
pull(start_station)
new_stations <- spc_2025 %>%
filter(Trip_Count > 0) %>%
distinct(start_station) %>%
pull(start_station)
# Keep only stations that appear in BOTH periods
common_stations <- intersect(early_stations, late_stations)
# eliminate trip counts from stations that only have trips in either the train/test data
study_panel_complete_filt <- study_panel_complete %>%
filter(start_station %in% common_stations)
cat("Percent data loss relative to original panel dataset after removing time-limited station counts: ",
round((1-nrow(study_panel_complete_filt)/nrow(study_panel_complete))*100, 2),
"%",
sep = "",
"\n")
spc_2024_filt <- study_panel_complete_filt %>% filter(year(interval60) == 2024)
spc_2025_filt <- study_panel_complete_filt %>% filter(year(interval60) == 2025)
# NOW create train/test split
train <- spc_2024_filt %>%
filter(week < 40)
test <- spc_2024_filt %>%
filter(week >= 40)
cat("Training observations:", format(nrow(train), big.mark = ","), "\n",
"Testing observations:", format(nrow(test), big.mark = ","), "\n",
"Training date range:", as.character(min(train$date)), "to", as.character(max(train$date)), "\n",
"Testing date range:", as.character(min(test$date)), "to", as.character(max(test$date)), "\n")
# Set contrasts to treatment coding (dummy variables)
contrasts(train$dotw_simple) <- contr.treatment(7)
# Now run the model
model1 <- lm(
Trip_Count ~ as.factor(hour) + dotw_simple + temp + prec,
data = train
)
summary(model1)
model2 <- lm(
Trip_Count ~ as.factor(hour) + dotw_simple + temp + prec +
lag1Hour + lag3Hours + lag1day,
data = train
)
summary(model2)
model3 <- lm(
Trip_Count ~ as.factor(hour) + dotw_simple + temp + prec +
lag1Hour + lag3Hours + lag1day +
Med_Inc + Percent_Taking_Transit + Percent_White,
data = train
)
summary(model3)
model4 <- lm(
Trip_Count ~ as.factor(hour) + dotw_simple + temp + prec +
lag1Hour + lag3Hours + lag1day +
Med_Inc + Percent_Taking_Transit + Percent_White +
as.factor(start_station),
data = train
)
# Summary too long with all station dummies, just show key metrics
cat("Model 4 R-squared:", summary(model4)$r.squared, "\n")
cat("Model 4 Adj R-squared:", summary(model4)$adj.r.squared, "\n")
model5 <- lm(
Trip_Count ~ as.factor(hour) + dotw_simple + temp + prec +
lag1Hour + lag3Hours + lag1day + rush_hour +
Med_Inc + Percent_Taking_Transit + Percent_White +
as.factor(start_station) +
rush_hour * weekend,  # Rush hour effects different on weekends
data = train
)
cat("Model 5 R-squared:", summary(model5)$r.squared, "\n")
cat("Model 5 Adj R-squared:", summary(model5)$adj.r.squared, "\n")
model6 <- lm(
Trip_Count ~
as.factor(hour) + dotw_simple + lag1Hour + lag3Hours + lag1day +
temp + wspd + rain +
Med_Inc + Percent_Taking_Transit + Percent_White +
business_dens + holiday,
data = train
)
summary(model6)
model7 <- glm(
Trip_Count ~
as.factor(hour) + dotw_simple + lag1Hour + lag3Hours + lag1day +
temp + wspd + rain +
Med_Inc + Percent_Taking_Transit + Percent_White +
business_dens + holiday,
family = "poisson",
data = train)
summary(model7)
# Get predictions on test set
# Set contrasts to treatment coding (dummy variables)
contrasts(test$dotw_simple) <- contr.treatment(7)
test <- test %>%
mutate(
pred1 = predict(model1, newdata = test),
pred2 = predict(model2, newdata = test),
pred3 = predict(model3, newdata = test),
pred4 = predict(model4, newdata = test),
pred5 = predict(model5, newdata = test),
pred6 = predict(model6, newdata = test),
pred7 = predict(model7, newdata = test)
)
spc_2025_filt <- spc_2025_filt %>%
mutate(
pred2 = predict(model2, newdata = spc_2025_filt),
pred6 = predict(model6, newdata = spc_2025_filt)
)
# Calculate MAE for each model
mae_results <- data.frame(
Model = c(
"1. Time + Weather",
"2. + Temporal Lags",
"3. + Demographics",
"4. + Station FE",
"5. + Rush Hour Interaction",
"6. Model 3 + Additional Variables",
"7. Poisson Regression of Model 6 Formula",
"8. Predicting for Q1 2025 - Model 2",
"9. Predicting for Q1 2025 - Model 6"
),
MAE = c(
mean(abs(test$Trip_Count - test$pred1), na.rm = TRUE),
mean(abs(test$Trip_Count - test$pred2), na.rm = TRUE),
mean(abs(test$Trip_Count - test$pred3), na.rm = TRUE),
mean(abs(test$Trip_Count - test$pred4), na.rm = TRUE),
mean(abs(test$Trip_Count - test$pred5), na.rm = TRUE),
mean(abs(test$Trip_Count - test$pred6), na.rm = TRUE),
mean(abs(test$Trip_Count - test$pred7), na.rm = TRUE),
mean(abs(spc_2025_filt$Trip_Count - spc_2025_filt$pred2), na.rm = TRUE),
mean(abs(spc_2025_filt$Trip_Count - spc_2025_filt$pred6), na.rm = TRUE)
)
)
kable(mae_results,
digits = 2,
caption = "Mean Absolute Error by Model (Test Set)",
col.names = c("Model", "MAE (trips)")) %>%
kable_styling(bootstrap_options = c("striped", "hover"))
# check MAE for Q1 2025
test <- test %>%
mutate(
error = Trip_Count - pred2,
abs_error = abs(error),
time_of_day = case_when(
hour < 7 ~ "Overnight",
hour >= 7 & hour < 10 ~ "AM Rush",
hour >= 10 & hour < 15 ~ "Mid-Day",
hour >= 15 & hour <= 18 ~ "PM Rush",
hour > 18 ~ "Evening"
)
)
# Scatter plot by time and day type
ggplot(test, aes(x = Trip_Count, y = pred2)) +
geom_point(alpha = 0.2, color = "#3182bd") +
geom_abline(slope = 1, intercept = 0, color = "red", linewidth = 1) +
geom_smooth(method = "lm", se = FALSE, color = "darkgreen") +
facet_grid(weekend ~ time_of_day) +
labs(
title = "Observed vs. Predicted Bike Trips",
subtitle = "Model 2 performance by time period",
x = "Observed Trips",
y = "Predicted Trips",
caption = "Red line = perfect predictions; Green line = actual model fit"
) +
theme_void()
# Calculate station errors
station_errors <- test %>%
filter(!is.na(pred2)) %>%
group_by(start_station, start_lat, start_lon) %>%
summarize(
MAE = mean(abs(Trip_Count - pred2), na.rm = TRUE),
avg_demand = mean(Trip_Count, na.rm = TRUE),
.groups = "drop"
) %>%
filter(!is.na(start_lat), !is.na(start_lon))
# Map 1: Prediction Errors
p1 <- ggplot() +
geom_sf(data = phl_census %>% st_transform(4326), fill = "grey95", color = "white", size = 0.1) +
geom_point(
data = station_errors,
aes(x = start_lon, y = start_lat, color = MAE),
size = 3.5,
alpha = 0.2
) +
scale_color_viridis(
option = "plasma",
name = "MAE (trips)",
direction = -1,
breaks = c(0.5, 1.0, 1.5),
labels = c("0.5", "1.0", "1.5")
) +
labs(title = "Prediction Errors") +
mapTheme +
theme(
legend.position = "bottom",
legend.title = element_text(size = 10, face = "bold"),
legend.text = element_text(size = 9),
plot.title = element_text(size = 14, face = "bold", hjust = 0.5)
) +
guides(color = guide_colorbar(
barwidth = 12,
barheight = 1,
title.position = "top",
title.hjust = 0.5
))
# Map 2: Average Demand
p2 <- ggplot() +
geom_sf(data = phl_census %>% st_transform(4326), fill = "grey95", color = "white", size = 0.1) +
geom_point(
data = station_errors,
aes(x = start_lon, y = start_lat, color = avg_demand),
size = 3.5,
alpha = 0.2
) +
scale_color_viridis(
option = "viridis",
name = "Avg Demand (trips/hour)",
direction = -1,
breaks = c(0.5, 1.0, 1.5, 2.0, 2.5),
labels = c("0.5", "1.0", "1.5", "2.0", "2.5")
) +
labs(title = "Average Demand") +
mapTheme +
theme(
legend.position = "bottom",
legend.title = element_text(size = 10, face = "bold"),
legend.text = element_text(size = 9),
plot.title = element_text(size = 14, face = "bold", hjust = 0.5)
) +
guides(color = guide_colorbar(
barwidth = 12,
barheight = 1,
title.position = "top",
title.hjust = 0.5
))
# Combine
grid.arrange(
p1, p2,
ncol = 2
)
# MAE by time of day and day type
temporal_errors <- test %>%
group_by(time_of_day, weekend) %>%
summarize(
MAE = mean(abs_error, na.rm = TRUE),
.groups = "drop"
) %>%
mutate(day_type = ifelse(weekend == 1, "Weekend", "Weekday"))
ggplot(temporal_errors, aes(x = time_of_day, y = MAE, fill = day_type)) +
geom_col(position = "dodge") +
scale_fill_manual(values = c("Weekday" = "#08519c", "Weekend" = "#6baed6")) +
labs(
title = "Prediction Errors by Time Period",
subtitle = "When is the model struggling most?",
x = "Time of Day",
y = "Mean Absolute Error (trips)",
fill = "Day Type"
) +
plotTheme +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Join demographic data to station errors
station_errors_demo <- station_errors %>%
left_join(stn_points_filt_panel %>%
select(start_station, GEOID),
by = "start_station") %>%
left_join(phl_census_select %>%
select(GEOID, Med_Inc, Percent_Taking_Transit, Percent_White),
by = "GEOID") %>%
filter(!is.na(Med_Inc))
# Create plots
p1 <- ggplot(station_errors_demo, aes(x = Med_Inc, y = MAE)) +
geom_point(alpha = 0.5, color = "#3182bd") +
geom_smooth(method = "lm", se = FALSE, color = "red") +
scale_x_continuous(labels = scales::dollar) +
labs(title = "Errors vs. Median Income", x = "Median Income", y = "MAE") +
plotTheme
p2 <- ggplot(station_errors_demo, aes(x = Percent_Taking_Transit, y = MAE)) +
geom_point(alpha = 0.5, color = "#3182bd") +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Errors vs. Transit Usage", x = "% Taking Transit", y = "MAE") +
plotTheme
p3 <- ggplot(station_errors_demo, aes(x = Percent_White, y = MAE)) +
geom_point(alpha = 0.5, color = "#3182bd") +
geom_smooth(method = "lm", se = FALSE, color = "red") +
labs(title = "Errors vs. Race", x = "% White", y = "MAE") +
plotTheme
grid.arrange(p1, p2, p3, ncol = 2)
setwd('./GitHub/MUSA-5080-Final/')
go to working directory
if(!require(pacman)){install.packages("pacman"); library(pacman, quietly = T)}
p_load(lubridate, sf, tidycensus, tidygeocoder, tidyverse, tigris, tmap, viridis)
set.seed(5746)
# load evictions dataset to investigate
evictions_df <- read_csv("./data/philadelphia_monthly_2020_2021.csv", show_col_types = F)
evictions_df <- evictions_df %>%
filter(GEOID != "sealed")
# generate vectors of all possible months and GEOIDs
months <- seq(as.Date("2020-01-01"),
as.Date("2025-11-01"),
install.packages(c("xfun", "knitr", rmarkdown))
install.packages("xfun")
install.packages("knitr")
install.packages("rmarkdown")
by = "month") %>%
format("%m/%Y")
geoids  <- unique(evictions_df$GEOID)
# expand a grid of GEOID/month combinations
geoids_months <- expand.grid(GEOID = geoids,
month = months,
stringsAsFactors = F)
# identify missing combinations
missing <- geoids_months %>%
anti_join(evictions_df %>% select(GEOID, month),
by = c("GEOID", "month"))
# print result
if (nrow(missing) > 0){
cat("Number of Missing GEOID/Month Combinations:", nrow(missing))
} else{
cat("No GEOID/Month Combinations Missing")
}
# designate FIPS codes for PA and Philly
fips_pa <- 42
fips_phl <- 101
# load tigris census tract boundaries
tracts <- tracts(state = 42, county = 101, year = 2020, progress_bar = F) %>%
select(GEOID) %>%
st_transform(2272)
# join to evictions dataset and make spatial
evictions <- left_join(evictions_df, tracts, by = "GEOID", ) %>%
st_as_sf()
# manufacture month and year columns, convert existing month column to 'date'
# evictions <- evictions %>%
#   rename(date = month) %>%
#   mutate(
#     month = month(my(date)),
#     year = year(my(date)),
#     filings_2020_log = log(filings_2020 + 1)
#   )
# Create proper date format
evictions <- evictions %>%
mutate(
month_date = as.Date(paste0("01/", month), format = "%d/%m/%Y"),
delta = filings_2020 - filings_avg_prepandemic_baseline,
ratio = filings_2020 / filings_avg_prepandemic_baseline
)
# Total filings per tract
tract_totals <- evictions %>%
group_by(GEOID) %>%
summarise(total_filings = sum(filings_2020, na.rm = TRUE))
#Plot
ggplot(tract_totals) +
geom_sf(aes(fill = total_filings),
color = "white", linewidth = 0.2) +
scale_fill_viridis_c(option = "C") +
labs(
title = "Total Eviction Filings by Census Tract",
subtitle = "Cumulative filings across all years in the dataset",
fill = "Total Filings"
) +
theme_void()
# Top 10 Tracts - Eviction Filing Hotspots
tract_totals %>%
arrange(desc(total_filings)) %>%
slice_head(n = 10)
# Bottom 10 Tracts
tract_totals %>%
arrange(total_filings) %>%
slice_head(n = 10)
# Create monthly evictions
eviction_monthly <- evictions %>%
group_by(month_date) %>%
summarise(total_filings = sum(filings_2020, na.rm = TRUE))
# Plot total monthly evictions
ggplot(eviction_monthly, aes(x = month_date, y = total_filings)) +
geom_line(color = "#3182bd", linewidth = 1) +             # blue line
geom_smooth(se = FALSE, color = "red", linetype = "dashed") +  # red trend line
labs(
title = "Monthly Eviction Filings",
subtitle = "Tract-level eviction filings aggregated across the city",
x = "Date",
y = "Total Filings",
caption = "Source: Eviction Court Filings"
)
evictions %>%
group_by(month_date, racial_majority) %>%
summarise(total_filings = sum(filings_2020, na.rm = TRUE), .groups = "drop") %>%
ggplot(aes(month_date, total_filings, color = racial_majority)) +
geom_line() +
labs(title = "Eviction Filings Over Time by Racial-Majority Tract",
x = "Date", y = "Total Filings",
color = "Racial Majority") +
theme_minimal()
# Create monthly evictions
# Filings_2020 = total eviction filings
ggplot(evictions %>% filter(filings_2020 <= 50),
aes(filings_2020)) +
geom_histogram(bins = 30, fill = "steelblue") +
labs(title = "Distribution of Monthly Filings per Tract (<= 50)",
x = "Filings", y = "Count")
# Distribution of Delta
ggplot(evictions, aes(delta)) +
geom_histogram(bins = 30, fill = "purple") +
labs(
title = "Delta: Filings vs Pre-Pandemic Baseline",
x = "Delta",
y = "Count"
)
# Distribution of Ratio
ggplot(evictions, aes(ratio)) +
geom_histogram(bins = 30, fill = "darkgreen") +
labs(
title = "Ratio of Filings to Baseline",
x = "Ratio",
y = "Count"
)
evictions %>%
group_by(racial_majority) %>%
summarise(mean_filings = mean(filings_2020, na.rm = TRUE)) %>%
ggplot(aes(racial_majority, mean_filings, fill = racial_majority)) +
geom_col() +
labs(
title = "Average Monthly Eviction Filings by Racial-Majority Tract",
x = "Racial Majority Group",
y = "Average Monthly Filings"
) +
theme_minimal() +
theme(legend.position = "none")
housing_sf <- st_read('./data/Affordable_Housing.geojson', quiet = T) %>%
st_transform(2272)
# filter out properties for which there is no year associated and geometry is not empty
housing <- housing_sf %>%
filter(!is.na(fiscal_year_complete),
!st_is_empty(.)) %>%
st_join(tracts, join = st_within)
ggplot() +
geom_sf(data = tracts,
fill = NA,
color = 'grey70') +
geom_sf(data = housing,
mapping = aes(size = total_units),
lwd = 0,
color = 'purple4',
alpha = 0.25) +
labs(title = "Affordable Housing in Philadelphia",
subtitle = "Locations and Total Unit Counts",
size = 'Total Units') +
theme_void()
housing_cnts <- housing %>%
st_drop_geometry() %>%
group_by(GEOID, fiscal_year_complete) %>%
summarise(n_proj = n(),
total_units = sum(total_units)) %>%
mutate(n_proj_cum = ave(n_proj, FUN = cumsum),
total_units_cum = ave(total_units, FUN = cumsum)) %>%
filter(fiscal_year_complete >= 2020) %>%
left_join(tracts, by = "GEOID") %>%
st_as_sf(crs = 2272)
ggplot() +
geom_sf(data = tracts, color = 'grey85', fill = NA) +
geom_sf(data = housing_cnts, aes(fill = total_units_cum)) +
facet_wrap(~fiscal_year_complete) +
theme_void()
# read in crime data
crime_df <- read_csv('./data/incidents_part1_part2.csv', show_col_types = F)
# filter out any entries that don't have a location
crime_df <- crime_df %>% filter(!if_any(c('point_x', 'point_y', 'lat', 'lng'), is.na))
crime <- crime_df %>% st_as_sf(coords=c('lng', 'lat'), crs=4326) %>%
st_transform(2272)
# join tract geoid to crimes and filter out those not in Philly
crime_tract <- st_join(crime, tracts, join = st_intersects) %>%
filter(!is.na(GEOID))
# summarize by the number of each type of crime per census tract
crime_cnts <- crime_tract %>%
st_drop_geometry() %>%
group_by(GEOID, text_general_code) %>%
summarise(count = n()) %>%
ungroup() %>%
complete(data = ., GEOID, text_general_code, fill = list(count = 0))
# read in results of
mva <- st_read('./data/mva_2023.geojson', quiet = T) %>%
st_transform(2272)
# the data is at the block group level
# GEOID (12 digits) = tract (11 digits) + block grp (1 digit)
mva <- mva %>%
mutate(GEOID_Tract = substr(geoid, 1, nchar(geoid)-1))
# create k-nearest neighbors function
get_knn_distance <- function(dist_matrix, k) {
apply(dist_matrix, 1, function(distances) {
mean(as.numeric(sort(distances)[1:k]))
})
}
# load housing counseling agency locations
hca <- st_read('./data/HousingCounselingAgencies.geojson', quiet = T) %>%
st_transform(2272)
# create centroids for each tract to calculate distances
tracts_cent <- tracts %>%
st_centroid()
# claculate distance matrix
hca_distmatrix <- st_distance(tracts_cent, hca)
# distance to the nearest 1 and nearest 3 HCAs
hca_dist <- tracts %>%
mutate(dist_1hca = get_knn_distance(hca_distmatrix, k = 1),
dist_3hca = get_knn_distance(hca_distmatrix, k = 3))
years <- c(2020:2023)
vars <- c('pop_tot' = 'B01003_001',   # total tract population
'pop_white' = 'B02001_002', # white population (for %-non-white calc)
'units_tot' = 'B25001_001', # total housing units
'hh_tot' = 'B11001_001',    # total households
'hh_fam' = 'B11001_002')    # family households)
demo_vars <- map_df(years, function(y) {
get_acs(
geography = "tract",
variables = vars,
year = y,
survey = "acs5",
state = fips_pa,
county = fips_phl,
progress_bar = F
) %>%
mutate(year = y)
})
# Total filings per tract
tract_totals <- evictions %>%
group_by(GEOID) %>%
summarise(total_filings = sum(filings_2020, na.rm = TRUE))
#Plot
ggplot(tract_totals) +
geom_sf(aes(fill = total_filings),
color = "white", linewidth = 0.2) +
scale_fill_viridis_c(option = "C") +
labs(
title = "Total Eviction Filings by Census Tract",
subtitle = "Cumulative filings across all years in the dataset",
fill = "Total Filings"
) +
theme_void()
View(evictions)
